{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from models import MetaRegression, BSS, SVDPortfolio\n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.linalg.svd.html\n",
    "from scipy.linalg import svd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import clone\n",
    "from statistics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VBS(performance, X_test):\n",
    "    \"\"\" chooses the best solver for each dataset\"\"\"\n",
    "    best_perf = performance.idxmax(axis=\"columns\")\n",
    "    return best_perf.loc[best_perf.index.isin(X_test.index)]\n",
    "\n",
    "# functie om van predictions de accuracies te berekenen\n",
    "def avg_accuracy(predicted_solvers, performance):\n",
    "    \"\"\" Calculates the average accuracy on dataset given the solvers for each dataset.\n",
    "    input:\n",
    "        predicted_solvers: dataframe with each row a dataset and predicted solver in column\n",
    "        performance: dataframe with each row a dataset and in each column the accuracy of a solver\n",
    "    return:\n",
    "        float avg accuracy\"\"\"\n",
    "    return np.mean(performance.lookup(predicted_solvers.index, predicted_solvers.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def find_largest_drop(df):\n",
    "    \"\"\"Find the biggest drop, returns cutoff value indicating\n",
    "    where the array should be cut off. Used for Chi squared filtering\"\"\"\n",
    "    drop = 0\n",
    "    cutoff_value = 0\n",
    "    names = df.index.names\n",
    "    for i in range(df.shape[0] - 1):\n",
    "        if df.iloc[i][0] - df.iloc[i+1][0] > drop:\n",
    "            cutoff_value = i\n",
    "            drop = df.iloc[i][0] - df.iloc[i+1][0]\n",
    "            \n",
    "    return cutoff_value\n",
    "\n",
    "\n",
    "def feature_filtering(X_train, X_test, y_train, model):\n",
    "    \"\"\"Returns X_train and X_test filtered using chi squared filtering \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "    # scale all values of features to range 0-1 because chi squared \n",
    "    # cannot handle negative values\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "    #get feature names\n",
    "    chi2_val, pval = chi2(pd.DataFrame(min_max_scaler.fit_transform(X_test.values)), predicted)\n",
    "    \n",
    "    #transform numpy array to dataframe to easily get the feature names\n",
    "    df = pd.DataFrame(data=pval, index=X_test.columns)    \n",
    "    #sort dataframe\n",
    "    df.sort_values(by=0, ascending=False, inplace=True)\n",
    "    \n",
    "    cutoff_value = find_largest_drop(df)\n",
    "    features = df.iloc[0:(cutoff_value+1)].index\n",
    "    \n",
    "    X_train_filtered = X_train[features]\n",
    "    X_test_filtered = X_test[features]\n",
    "    return  X_train_filtered,  X_test_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossval10fold(X, y, model, filtering=False):\n",
    "    kfold = KFold(n_splits=10)\n",
    "    accuracy = []\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], metafeatures.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        if filtering:\n",
    "            X_train, X_test = feature_filtering(X_train, X_test, y_train, model)\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy.append(avg_accuracy(model.predict(X_test), y))\n",
    "    return mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"metadata.csv\",usecols=[\"task_id\",\"flow_id\",\"value\"]).set_index(\"task_id\")\n",
    "metadata = metadata.pivot_table('value', ['task_id'],'flow_id')\n",
    "data= arff.loadarff('metafeatures-CC18.arff')\n",
    "metafeatures = pd.DataFrame(data[0]).set_index(\"task_id\")\n",
    "metafeatures = metafeatures.loc[metafeatures.index.isin(metadata.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_models = {\n",
    "    \"Tree\":DecisionTreeRegressor(random_state=0),\n",
    "    \"Linear\":LinearRegression(),\n",
    "    \"SVM\":SVR(),\n",
    "    \"KNN\":KNeighborsRegressor(),\n",
    "    \"Forest-500\":RandomForestRegressor(n_estimators=500)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BSS:  0.8600244008716666\n",
      "Tree :  0.84309526655\n",
      "Linear :  0.8144249023483333\n",
      "SVM :  0.8585198156566667\n",
      "KNN :  0.85774618276\n",
      "Forest-500 :  0.843052682075\n",
      "VBS:  0.87159010936\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10)\n",
    "solver_list = metadata.columns.to_list()\n",
    "\n",
    "print(\"BSS: \", crossval10fold(metafeatures,metadata,BSS(solver_list)))\n",
    "\n",
    "for model in regression_models:\n",
    "    print(model, \": \", crossval10fold(metafeatures,metadata,MetaRegression(solver_list,clone(regression_models[model]))))\n",
    "\n",
    "vbs_accuracy=[]\n",
    "for train_index, test_index in kfold.split(metafeatures):\n",
    "    X_train, X_test = metafeatures.iloc[train_index], metafeatures.iloc[test_index]\n",
    "    vbs_accuracy.append(avg_accuracy(VBS(metadata,X_test), metadata))\n",
    "print(\"VBS: \", mean(vbs_accuracy))\n",
    "\n",
    "# hmm bss is niet de slechtste, dat is vreemd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature filtering </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Retraining of models using chi squared filtering\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c00e71059a59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregression_models\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrossval10fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetafeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMetaRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f23810465a65>\u001b[0m in \u001b[0;36mcrossval10fold\u001b[0;34m(X, y, model, filtering)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Retraining of models using chi squared filtering\")\n",
    "for model in regression_models:\n",
    "\n",
    "    print(model, \": \", crossval10fold(metafeatures,metadata,MetaRegression(solver_list,clone(regression_models[model])), True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Singular value decomposition </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_crossval(X,model,filtering=0):\n",
    "    accuracy = []\n",
    "    for i in range(10):\n",
    "        X_train = X.sample(frac = 0.9)\n",
    "        U, s, Vh = svd(X_train)\n",
    "        df_U = pd.DataFrame(index = X_train.index)\n",
    "        #m > n dus alleen eerste n cols zijn nodig\n",
    "        U = U[:,:X_train.shape[1]-0]\n",
    "        for i in range(U.shape[1]):\n",
    "            df_U[i] = U[:,i]\n",
    "        X_test = X.dot(Vh.T).dot(np.linalg.inv(np.diag(s)))\n",
    "\n",
    "        y_train, y_test = X.loc[df_U.index,:], X.loc[df_U.index,:]\n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy.append(avg_accuracy(model.predict(X_test), X))\n",
    "    return mean(accuracy)"
   ]
  },
  {
   "source": [
    "<h2> SVD feature filtering </h2>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of latent features:  10\n",
      "Accuracy results after filtering out  0  latent feature(s)\n",
      "Tree:  0.7234742424976667\n",
      "Linear:  0.8112901873168333\n",
      "SVM:  0.8597770403643332\n",
      "KNN:  0.8534350029233334\n",
      "Forest-500:  0.8473332460838333\n",
      "Accuracy results after filtering out  1  latent feature(s)\n",
      "Tree:  0.7237499172796666\n",
      "Linear:  0.8336603551245\n",
      "SVM:  0.8593654610768332\n",
      "KNN:  0.8524398226028334\n",
      "Forest-500:  0.8406587364626666\n",
      "Accuracy results after filtering out  2  latent feature(s)\n",
      "Tree:  0.7373680603358334\n",
      "Linear:  0.8210012501315\n",
      "SVM:  0.8598104410166666\n",
      "KNN:  0.8534350029233334\n",
      "Forest-500:  0.8423247914655\n",
      "Accuracy results after filtering out  3  latent feature(s)\n",
      "Tree:  0.724755351571\n",
      "Linear:  0.8245324341415\n",
      "SVM:  0.8590092067611665\n",
      "KNN:  0.8534350029233334\n",
      "Forest-500:  0.840630959301\n",
      "Accuracy results after filtering out  4  latent feature(s)\n",
      "Tree:  0.7362343988765\n",
      "Linear:  0.8187939527221667\n",
      "SVM:  0.8599196800064999\n",
      "KNN:  0.8534350029233334\n",
      "Forest-500:  0.8488456072781667\n",
      "Accuracy results after filtering out  5  latent feature(s)\n",
      "Tree:  0.7362322900533333\n",
      "Linear:  0.8186606655816667\n",
      "SVM:  0.8600244008716665\n",
      "KNN:  0.8524398226028334\n",
      "Forest-500:  0.844017874038\n",
      "Accuracy results after filtering out  6  latent feature(s)\n",
      "Tree:  0.7589515725888334\n",
      "Linear:  0.8184858592750001\n",
      "SVM:  0.8598439371491665\n",
      "KNN:  0.8534350029233334\n",
      "Forest-500:  0.8420165202118334\n",
      "Accuracy results after filtering out  7  latent feature(s)\n",
      "Tree:  0.7468699821823334\n",
      "Linear:  0.8179475605251667\n",
      "SVM:  0.8600244008716665\n",
      "KNN:  0.8534350029233334\n",
      "Forest-500:  0.8419189114385001\n",
      "Accuracy results after filtering out  8  latent feature(s)\n",
      "Tree:  0.7244379123471667\n",
      "Linear:  0.8207452075798334\n",
      "SVM:  0.8595508554363332\n",
      "KNN:  0.8534350029233334\n",
      "Forest-500:  0.8473283142523333\n"
     ]
    }
   ],
   "source": [
    "# feature filtering with SVD\n",
    "print(\"Total number of latent features: \", metadata.shape[1])\n",
    "\n",
    "for i in range(9):\n",
    "    print(\"Accuracy results after filtering out \",i,\" latent feature(s)\")\n",
    "    print(\"Tree: \", latent_crossval(metadata,MetaRegression(solver_list,DecisionTreeRegressor(random_state=0)),i))\n",
    "    print(\"Linear: \", latent_crossval(metadata,MetaRegression(solver_list,LinearRegression()),i))\n",
    "    print(\"SVM: \", latent_crossval(metadata,MetaRegression(solver_list,SVR())))\n",
    "    print(\"KNN: \", latent_crossval(metadata,MetaRegression(solver_list,KNeighborsRegressor()),i))\n",
    "    print(\"Forest-500: \", latent_crossval(metadata,MetaRegression(solver_list,RandomForestRegressor(n_estimators=500)),i))\n",
    "    print(\"\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Estimating latent features </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Latent feature estimation with regression crossval scores\n",
      "Tree:  -2.9955405689906516\n",
      "Linear:  -262991.03787518444\n",
      "SVM:  nan\n",
      "KNN:  -1.0031830926869196\n",
      "Forest-500:  -0.5114764117777918\n"
     ]
    }
   ],
   "source": [
    "# U& Vh unitary matrices, s is 1d array met positieve scalars\n",
    "# a == U @ S@ Vh met S matrix met nullen en s op diag\n",
    "\n",
    "U, s, Vh = svd(metadata)\n",
    "df_U = pd.DataFrame(index = metadata.index)\n",
    "#m > n dus alleen eerste n cols zijn nodig\n",
    "for i in range(metadata.shape[1]):\n",
    "    df_U[i] = U[:,i]\n",
    "\n",
    "print(\"Latent feature estimation with regression R^2 scores\")\n",
    "\n",
    "cv = KFold(n_splits=10)\n",
    "\n",
    "print(\"Tree: \", mean(cross_val_score(DecisionTreeRegressor(random_state=0), metafeatures, df_U, cv=cv, n_jobs=1)))\n",
    "\n",
    "print(\"Linear: \", mean(cross_val_score(LinearRegression(), metafeatures, df_U, cv=cv, n_jobs=1)))\n",
    "\n",
    "print(\"SVM: \", mean(cross_val_score(SVR(), metafeatures.to_numpy(), df_U.to_numpy(), cv=cv, n_jobs=1,scoring=\"r2\")))\n",
    "\n",
    "print(\"KNN: \", mean(cross_val_score(KNeighborsRegressor(), metafeatures.to_numpy(), df_U.to_numpy(), cv=cv, n_jobs=1)))\n",
    "\n",
    "print(\"Forest-500: \", mean(cross_val_score(RandomForestRegressor(n_estimators=500), metadata, df_U, cv=cv, n_jobs=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVDportfolio, no filtering:  0.8629734388166667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"SVDportfolio, no filtering: \", crossval10fold(metafeatures,metadata, SVDPortfolio(metadata.columns.to_list(), LinearRegression(),RandomForestRegressor(n_estimators=500))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}